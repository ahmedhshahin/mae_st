python3 -m torch.distributed.run --nproc_per_node=$WORLD_SIZE run_pretrain.py \
 --path_to_osic_data_dir /SAN/medic/IPF/segmentations/osic_mar_23_unpadded/ \
 --path_to_lsut_data_dir /cluster/project0/LUST_SSL/lsut_resampled_z256256_lungonly_h5/ \
 --path_to_df ct_data.csv \
 --model mae_vit_large_patch16 \
 --num_slices 16 \
 --decoder_embed_dim 512 \
 --decoder_depth 4 \
 --pin_mem \
 --blr 1.6e-3 \
 --log_dir ./output_dir \
 --batch_size 16 \
 --mask_ratio 0.9 \
 --norm_pix_loss \
 --pred_t_dim 16 \
 --clip_grad 0.02 \
 --warmup_epochs 5 \
 --epochs 400 \
 --output_dir /SAN/medic/IPF/mae_st_exps/mae_st \
 --num_workers 8 \
 --checkpoint_period 50 \
 --distributed \
 --accum_iter 2 \
 --mean 0.6894 \
 --std 0.3069 \